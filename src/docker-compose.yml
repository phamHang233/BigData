
version: "3"
services:
  spark-submit-app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - SPARK_APPLICATION_PYTHON_LOCATION=/app/app.py
    volumes:
      - ./app:/app
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2

  node01:
      image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
      container_name: node01
      volumes:
        - ./data/node01:/hadoop/dfs/name
      environment:
        - CLUSTER_NAME=test
      env_file:
        - ./hadoop.env
      ports:
        - 50070:50070
        - 8020:8020

  node02:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    depends_on:
      - node01
    volumes:
      - ./data/node02:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.2
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.2
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
